{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Optuna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.dataloader import create_dataloader\n",
    "from src.loss import CustomCriterion\n",
    "from src.model import Model\n",
    "from src.trainer import TorchTrainer\n",
    "from src.utils.common import get_label_counts, read_yaml\n",
    "from src.utils.macs import calc_macs\n",
    "from src.utils.torch_utils import check_runtime, model_info\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"Base model class.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: Union[str, Dict[str, Type]] = \"./model_configs/show_case.yaml\",\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Parse model from the model config file.\n",
    "\n",
    "        Args:\n",
    "            cfg: yaml file path or dictionary type of the model.\n",
    "            verbose: print the model parsing information.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_parser = ModelParser(cfg=cfg, verbose=verbose)\n",
    "        self.model = self.model_parser.model\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward.\"\"\"\n",
    "        return self.forward_one(x)\n",
    "\n",
    "    def forward_one(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward onetime.\"\"\"\n",
    "\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelParser:\n",
    "    \"\"\"Generate PyTorch model from the model yaml file.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: Union[str, Dict[str, Type]] = \"./model_configs/show_case.yaml\",\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"Generate PyTorch model from the model yaml file.\n",
    "\n",
    "        Args:\n",
    "            cfg: model config file or dict values read from the model config file.\n",
    "            verbose: print the parsed model information.\n",
    "        \"\"\"\n",
    "\n",
    "        self.verbose = verbose\n",
    "        if isinstance(cfg, dict):\n",
    "            self.cfg = cfg\n",
    "        else:\n",
    "            with open(cfg) as f:\n",
    "                self.cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "        self.in_channel = self.cfg[\"input_channel\"]\n",
    "\n",
    "        self.depth_multiply = self.cfg[\"depth_multiple\"]\n",
    "        self.width_multiply = self.cfg[\"width_multiple\"]\n",
    "\n",
    "        # error: Incompatible types in assignment (expression has type \"Type[Any]\",\n",
    "        # variable has type \"List[Union[int, str, float]]\")\n",
    "        self.model_cfg: List[Union[int, str, float]] = self.cfg[\"backbone\"]  # type: ignore\n",
    "\n",
    "        self.model = self._parse_model()\n",
    "\n",
    "    def log(self, msg: str):\n",
    "        \"\"\"Log.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(msg)\n",
    "\n",
    "    def _parse_model(self) -> nn.Sequential:\n",
    "        \"\"\"Parse model.\"\"\"\n",
    "        layers: List[nn.Module] = []\n",
    "        log: str = (\n",
    "            f\"{'idx':>3} | {'n':>3} | {'params':>10} \"\n",
    "            f\"| {'module':>15} | {'arguments':>20} | {'in_channel':>12} | {'out_channel':>13}\"\n",
    "        )\n",
    "        self.log(log)\n",
    "        self.log(len(log) * \"-\")  # type: ignore\n",
    "\n",
    "        in_channel = self.in_channel\n",
    "        for i, (repeat, module, args) in enumerate(self.model_cfg):  # type: ignore\n",
    "            repeat = (\n",
    "                max(round(repeat * self.depth_multiply), 1) if repeat > 1 else repeat\n",
    "            )\n",
    "\n",
    "            module_generator = ModuleGenerator(module, in_channel)(  # type: ignore\n",
    "                *args,\n",
    "                width_multiply=self.width_multiply,\n",
    "            )\n",
    "            m = module_generator(repeat=repeat)\n",
    "\n",
    "            layers.append(m)\n",
    "            in_channel = module_generator.out_channel\n",
    "\n",
    "            log = (\n",
    "                f\"{i:3d} | {repeat:3d} | \"\n",
    "                f\"{m.n_params:10,d} | {m.type:>15} | {str(args):>20} | \"\n",
    "                f\"{str(module_generator.in_channel):>12}\"\n",
    "                f\"{str(module_generator.out_channel):>13}\"\n",
    "            )\n",
    "\n",
    "            self.log(log)\n",
    "\n",
    "        parsed_model = nn.Sequential(*layers)\n",
    "        n_param = sum([x.numel() for x in parsed_model.parameters()])\n",
    "        n_grad = sum([x.numel() for x in parsed_model.parameters() if x.requires_grad])\n",
    "        # error: Incompatible return value type (got \"Tuple[Sequential, List[int]]\",\n",
    "        # expected \"Tuple[Module, List[Optional[int]]]\")\n",
    "        self.log(\n",
    "            f\"Model Summary: {len(list(parsed_model.modules())):,d} \"\n",
    "            f\"layers, {n_param:,d} parameters, {n_grad:,d} gradients\"\n",
    "        )\n",
    "\n",
    "        return parsed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}